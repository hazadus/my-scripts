#!/usr/bin/env -S uv run --quiet --script
# /// script
# dependencies = [
#     "feedparser",
#     "httpx",
# ]
# ///
"""
RSS OPML Reader

–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OPML —Ñ–∞–π–ª–∞–º–∏ RSS –ª–µ–Ω—Ç.
"""

import argparse
import asyncio
import re
import ssl
import sys
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from pathlib import Path

import feedparser
import httpx


# MARK: main
def main():
    parser = argparse.ArgumentParser(
        description="–ü–∞—Ä—Å–µ—Ä OPML —Ñ–∞–π–ª–æ–≤ –¥–ª—è RSS –ª–µ–Ω—Ç",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  %(prog)s feeds.opml --list              # –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö RSS –ª–µ–Ω—Ç
  %(prog)s feeds.opml -l                  # –ö–æ—Ä–æ—Ç–∫–∞—è —Ñ–æ—Ä–º–∞ —Ñ–ª–∞–≥–∞ --list
  %(prog)s feeds.opml --read 2025-01-15   # –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å—Ç—ã –∑–∞ 15 —è–Ω–≤–∞—Ä—è 2025
  %(prog)s feeds.opml --read 2025-01-15 --markdown  # –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown
        """,
    )

    parser.add_argument("opml_file", help="–ü—É—Ç—å –∫ OPML —Ñ–∞–π–ª—É")

    parser.add_argument(
        "--list",
        "-l",
        action="store_true",
        help="–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö RSS URL –∏–∑ —Ñ–∞–π–ª–∞",
    )

    parser.add_argument(
        "--read",
        metavar="YYYY-MM-DD",
        help="–í—ã–≤–µ—Å—Ç–∏ –ø–æ—Å—Ç—ã –∏–∑ –≤—Å–µ—Ö –ª–µ–Ω—Ç –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É (—Ñ–æ—Ä–º–∞—Ç: YYYY-MM-DD)",
    )

    parser.add_argument(
        "--silent",
        action="store_true",
        help="–ù–µ –≤—ã–≤–æ–¥–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –æ—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–µ–Ω—Ç –ø–æ—Å–ª–µ –æ—Ç—á–µ—Ç–∞",
    )

    parser.add_argument(
        "--markdown",
        action="store_true",
        help="–í—ã–≤–æ–¥–∏—Ç—å –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown",
    )

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    opml_path = Path(args.opml_file)
    if not opml_path.exists():
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª '{args.opml_file}' –Ω–µ –Ω–∞–π–¥–µ–Ω", file=sys.stderr)
        sys.exit(1)

    # –ü–∞—Ä—Å–∏–º OPML —Ñ–∞–π–ª
    feeds = parse_opml(file_path=args.opml_file)

    # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–ª–∞–≥–æ–≤
    if args.list:
        list_feeds(feeds=feeds, silent=args.silent)
    elif args.read:
        async_read_posts_wrapper(
            feeds=feeds, date_str=args.read, silent=args.silent, markdown=args.markdown
        )
    else:
        # –ï—Å–ª–∏ –Ω–∏–∫–∞–∫–∏–µ —Ñ–ª–∞–≥–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫—É—é —Å–ø—Ä–∞–≤–∫—É
        if not args.silent:
            print(f"–§–∞–π–ª '{args.opml_file}' —Å–æ–¥–µ—Ä–∂–∏—Ç {len(feeds)} RSS –ª–µ–Ω—Ç.")
            print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–ª–∞–≥ --list –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–ø–∏—Å–∫–∞ –ª–µ–Ω—Ç.")
            print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–ª–∞–≥ --read YYYY-MM-DD –¥–ª—è —á—Ç–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤ –∑–∞ –¥–∞—Ç—É.")
            print("–î–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–π —Å–ø—Ä–∞–≤–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ --help")


# MARK: parse_opml
def parse_opml(
    *,
    file_path: str,
):
    """
    –ü–∞—Ä—Å–∏—Ç OPML —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ RSS URL.

    Args:
        file_path (str): –ü—É—Ç—å –∫ OPML —Ñ–∞–π–ª—É

    Returns:
        list: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ RSS –ª–µ–Ω—Ç–∞—Ö
    """
    try:
        tree = ET.parse(file_path)
        root = tree.getroot()

        feeds = []

        # –ò—â–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã outline —Å –∞—Ç—Ä–∏–±—É—Ç–æ–º xmlUrl
        for outline in root.findall(".//outline[@xmlUrl]"):
            feed_info = {
                "title": outline.get("title", outline.get("text", "Unknown")),
                "url": outline.get("xmlUrl"),
                "website": outline.get("htmlUrl", ""),
                "description": outline.get("description", ""),
            }
            feeds.append(feed_info)

        return feeds

    except ET.ParseError as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {e}", file=sys.stderr)
        sys.exit(1)
    except FileNotFoundError:
        print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}", file=sys.stderr)
        sys.exit(1)


# MARK: list_feeds
def list_feeds(
    *,
    feeds: list[dict],
    silent: bool = False,
):
    """
    –í—ã–≤–æ–¥–∏—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö RSS URL.

    Args:
        feeds (list): –°–ø–∏—Å–æ–∫ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ RSS –ª–µ–Ω—Ç–∞—Ö
        silent (bool): –ù–µ –≤—ã–≤–æ–¥–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    """
    if not feeds:
        print("RSS –ª–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ñ–∞–π–ª–µ OPML")
        return

    if not silent:
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(feeds)} RSS –ª–µ–Ω—Ç:")
        print("-" * 50)

    for i, feed in enumerate(feeds, 1):
        print(f"{i:3d}. {feed['title']}")
        print(f"     URL: {feed['url']}")
        if feed["website"]:
            print(f"     –°–∞–π—Ç: {feed['website']}")
        if feed["description"]:
            print(f"     –û–ø–∏—Å–∞–Ω–∏–µ: {feed['description']}")
        print()


# MARK: parse_date_argument
def parse_date_argument(
    *,
    date_str: str,
):
    """
    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É –¥–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD.

    Args:
        date_str (str): –°—Ç—Ä–æ–∫–∞ –¥–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD

    Returns:
        tuple: (start_datetime, end_datetime) –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Å—É—Ç–æ–∫
    """
    try:
        date_obj = datetime.strptime(date_str, "%Y-%m-%d")
        start_datetime = date_obj
        end_datetime = date_obj + timedelta(days=1)
        return start_datetime, end_datetime
    except ValueError:
        print(
            f"–û—à–∏–±–∫–∞: –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã '{date_str}'. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD",
            file=sys.stderr,
        )
        sys.exit(1)


# MARK: get_feed_posts
async def get_feed_posts(
    *,
    client: httpx.AsyncClient,
    url: str,
    start_date: datetime,
    end_date: datetime,
    max_retries: int = 2,
    silent: bool = False,
    errors_list: list = None,
):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å—Ç—ã –∏–∑ RSS –ª–µ–Ω—Ç—ã –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏.

    Args:
        client (httpx.AsyncClient): HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
        url (str): URL RSS –ª–µ–Ω—Ç—ã
        start_date (datetime): –ù–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞
        end_date (datetime): –ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞
        max_retries (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
        silent (bool): –ù–µ –≤—ã–≤–æ–¥–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        errors_list (list): –°–ø–∏—Å–æ–∫ –¥–ª—è —Å–±–æ—Ä–∞ –æ—à–∏–±–æ–∫ (–≤ —Ä–µ–∂–∏–º–µ silent)

    Returns:
        list: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
    """
    if errors_list is None:
        errors_list = []

    for attempt in range(max_retries + 1):
        try:
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ (30 —Å–µ–∫—É–Ω–¥ –æ–±—â–∏–π —Ç–∞–π–º–∞—É—Ç)
            response = await client.get(url, timeout=30.0)
            response.raise_for_status()

            # –ü–∞—Ä—Å–∏–º RSS –ª–µ–Ω—Ç—É
            feed = feedparser.parse(response.content)

            posts = []
            for entry in feed.entries:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                published_time = None
                if hasattr(entry, "published_parsed") and entry.published_parsed:
                    published_time = datetime(*entry.published_parsed[:6])
                elif hasattr(entry, "updated_parsed") and entry.updated_parsed:
                    published_time = datetime(*entry.updated_parsed[:6])

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–ø–∞–¥–∞–µ—Ç –ª–∏ –ø–æ—Å—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
                if published_time and start_date <= published_time < end_date:
                    post_info = {
                        "title": entry.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                        "link": entry.get("link", ""),
                        "published": published_time,
                        "feed_title": feed.feed.get("title", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ª–µ–Ω—Ç–∞"),
                        "description": entry.get("summary", ""),
                    }
                    posts.append(post_info)

            return posts

        except httpx.HTTPStatusError as e:
            if e.response.status_code == 429:
                error_msg = f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ {url} (429). –ü—Ä–æ–ø—É—Å–∫–∞–µ–º."
                if silent:
                    errors_list.append(error_msg)
                else:
                    print(error_msg, file=sys.stderr)
            elif e.response.status_code == 403:
                error_msg = f"–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω –∫ {url} (403). –ü—Ä–æ–ø—É—Å–∫–∞–µ–º."
                if silent:
                    errors_list.append(error_msg)
                else:
                    print(error_msg, file=sys.stderr)
            elif e.response.status_code == 404:
                error_msg = f"–õ–µ–Ω—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ {url} (404). –ü—Ä–æ–ø—É—Å–∫–∞–µ–º."
                if silent:
                    errors_list.append(error_msg)
                else:
                    print(error_msg, file=sys.stderr)
            else:
                error_msg = f"HTTP –æ—à–∏–±–∫–∞ {e.response.status_code} –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}"
                if silent:
                    errors_list.append(error_msg)
                else:
                    print(error_msg, file=sys.stderr)
            return []
        except (httpx.TimeoutException, httpx.ConnectTimeout, httpx.ReadTimeout) as e:
            error_type = type(e).__name__
            if attempt < max_retries:
                wait_time = (attempt + 1) * 2  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                error_msg = f"–¢–∞–π–º–∞—É—Ç ({error_type}) –¥–ª—è {url}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries + 1}. –ñ–¥–µ–º {wait_time}—Å..."
                if not silent:
                    print(error_msg, file=sys.stderr)
                await asyncio.sleep(wait_time)
                continue
            else:
                error_msg = f"–¢–∞–π–º–∞—É—Ç ({error_type}) –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ª–µ–Ω—Ç—ã {url} –ø–æ—Å–ª–µ {max_retries + 1} –ø–æ–ø—ã—Ç–æ–∫: {e}"
                if silent:
                    errors_list.append(error_msg)
                else:
                    print(error_msg, file=sys.stderr)
                return []
        except httpx.ConnectError as e:
            if attempt < max_retries:
                wait_time = (attempt + 1) * 2
                error_msg = f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ {url}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries + 1}. –ñ–¥–µ–º {wait_time}—Å..."
                if not silent:
                    print(error_msg, file=sys.stderr)
                await asyncio.sleep(wait_time)
                continue
            else:
                error_msg = (
                    f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ {url} –ø–æ—Å–ª–µ {max_retries + 1} –ø–æ–ø—ã—Ç–æ–∫: {e}"
                )
                if silent:
                    errors_list.append(error_msg)
                else:
                    print(error_msg, file=sys.stderr)
                return []
        except httpx.UnsupportedProtocol as e:
            error_msg = f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª –¥–ª—è {url}: {e}"
            if silent:
                errors_list.append(error_msg)
            else:
                print(error_msg, file=sys.stderr)
            return []
        except httpx.TooManyRedirects as e:
            error_msg = f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π –¥–ª—è {url}: {e}"
            if silent:
                errors_list.append(error_msg)
            else:
                print(error_msg, file=sys.stderr)
            return []
        except httpx.InvalidURL as e:
            error_msg = f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL {url}: {e}"
            if silent:
                errors_list.append(error_msg)
            else:
                print(error_msg, file=sys.stderr)
            return []
        except ssl.SSLError as e:
            if attempt < max_retries:
                wait_time = (attempt + 1) * 2
                error_msg = f"SSL –æ—à–∏–±–∫–∞ –¥–ª—è {url}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries + 1}. –ñ–¥–µ–º {wait_time}—Å..."
                if not silent:
                    print(error_msg, file=sys.stderr)
                await asyncio.sleep(wait_time)
                continue
            else:
                error_msg = f"SSL –æ—à–∏–±–∫–∞ –¥–ª—è {url} –ø–æ—Å–ª–µ {max_retries + 1} –ø–æ–ø—ã—Ç–æ–∫: {e}"
                if silent:
                    errors_list.append(error_msg)
                else:
                    print(error_msg, file=sys.stderr)
                return []
        except httpx.RequestError as e:
            # –õ–æ–≤–∏–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–µ—Ç–µ–≤—ã–µ –æ—à–∏–±–∫–∏
            error_type = type(e).__name__
            if attempt < max_retries and "timeout" in str(e).lower():
                wait_time = (attempt + 1) * 2
                error_msg = f"–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ ({error_type}) –¥–ª—è {url}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries + 1}. –ñ–¥–µ–º {wait_time}—Å..."
                if not silent:
                    print(error_msg, file=sys.stderr)
                await asyncio.sleep(wait_time)
                continue
            else:
                error_msg = (
                    f"–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ ({error_type}) –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ª–µ–Ω—Ç—ã {url}: {e}"
                )
                if silent:
                    errors_list.append(error_msg)
                else:
                    print(error_msg, file=sys.stderr)
                return []
        except Exception as e:
            error_msg = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ª–µ–Ω—Ç—ã {url}: {e}"
            if silent:
                errors_list.append(error_msg)
            else:
                print(error_msg, file=sys.stderr)
            return []

    # –≠—Ç–æ—Ç return –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–æ—Å—Ç–∏–≥–Ω—É—Ç
    return []


# MARK: format_posts_markdown
def format_posts_markdown(
    *,
    posts: list[dict],
    date_str: str,
) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø–æ—Å—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.

    Args:
        posts (list): –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤
        date_str (str): –î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD

    Returns:
        str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –≤ Markdown
    """
    if not posts:
        return f"## –ü–æ—Å—Ç—ã –∑–∞ {date_str}\n\n–í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: 0\n\n–ü–æ—Å—Ç—ã –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç—á–µ—Ç–∞
    output = f"## –ü–æ—Å—Ç—ã –∑–∞ {date_str}\n\n"
    output += f"–í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: {len(posts)}\n\n"
    output += "----\n\n"

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –ø–æ—Å—Ç
    for post in posts:
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ—Å—Ç–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –ª–µ–Ω—Ç—ã
        output += f"### {post['title']} ({post['feed_title']})\n\n"

        # –°—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ—Å—Ç
        if post["link"]:
            output += f"üîó {post['link']}\n\n"

        # –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ—Å—Ç–∞
        if post["description"]:
            # –û—á–∏—â–∞–µ–º HTML-—Ç–µ–≥–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è (–ø—Ä–æ—Å—Ç–∞—è –æ—á–∏—Å—Ç–∫–∞)
            clean_desc = re.sub(r"<[^>]+>", "", post["description"])
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ–ø–∏—Å–∞–Ω–∏—è
            if len(clean_desc) > 300:
                clean_desc = clean_desc[:300] + "..."
            output += f"üí¨ {clean_desc}\n\n"

        output += "---\n\n"

    return output


# MARK: read_posts_for_date
async def read_posts_for_date(
    *,
    feeds: list[dict],
    date_str: str,
    silent: bool = False,
    markdown: bool = False,
):
    """
    –ß–∏—Ç–∞–µ—Ç –ø–æ—Å—Ç—ã –∏–∑ –≤—Å–µ—Ö –ª–µ–Ω—Ç –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É.

    Args:
        feeds (list): –°–ø–∏—Å–æ–∫ RSS –ª–µ–Ω—Ç
        date_str (str): –î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
        silent (bool): –ù–µ –≤—ã–≤–æ–¥–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        markdown (bool): –í—ã–≤–æ–¥–∏—Ç—å –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown
    """
    start_date, end_date = parse_date_argument(date_str=date_str)

    if not silent:
        print(f"–ü–æ–∏—Å–∫ –ø–æ—Å—Ç–æ–≤ –∑–∞ {date_str}...")
        print("-" * 50)

    all_posts = []
    errors_list = []

    # –°–æ–∑–¥–∞–µ–º HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    async with httpx.AsyncClient(
        timeout=httpx.Timeout(30.0, connect=10.0, read=20.0),  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã
        limits=httpx.Limits(
            max_connections=5, max_keepalive_connections=3
        ),  # –£–º–µ–Ω—å—à–∞–µ–º –Ω–∞–≥—Ä—É–∑–∫—É
        follow_redirects=True,
        max_redirects=10,
        headers={
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "application/rss+xml, application/xml, text/xml, application/atom+xml, */*",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept-Language": "en-US,en;q=0.9",
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        },
        verify=True,  # –ü—Ä–æ–≤–µ—Ä—è–µ–º SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã
    ) as client:
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        tasks = []
        for feed in feeds:
            if not silent:
                print(f"–î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å: {feed['title']}")
            task = get_feed_posts(
                client=client,
                url=feed["url"],
                start_date=start_date,
                end_date=end_date,
                silent=silent,
                errors_list=errors_list,
            )
            tasks.append(task)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        if not silent:
            print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º {len(tasks)} RSS –ª–µ–Ω—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ...")
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for result in results:
            if isinstance(result, list):
                all_posts.extend(result)
            elif isinstance(result, Exception):
                error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ª–µ–Ω—Ç—ã: {result}"
                if silent:
                    errors_list.append(error_msg)
                else:
                    print(error_msg, file=sys.stderr)

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ—Å—Ç—ã –ø–æ –¥–∞—Ç–µ (–æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º)
    all_posts.sort(key=lambda x: x["published"])

    if markdown:
        # –í—ã–≤–æ–¥–∏–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown
        markdown_output = format_posts_markdown(posts=all_posts, date_str=date_str)
        print(markdown_output)

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ –ø–æ—Å–ª–µ –æ—Ç—á–µ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ silent
        if silent and errors_list:
            print("\n–û—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–µ–Ω—Ç:", file=sys.stderr)
            for error in errors_list:
                print(f"  {error}", file=sys.stderr)
        return

    if not silent:
        print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(all_posts)} –ø–æ—Å—Ç–æ–≤ –∑–∞ {date_str}:")
        print("=" * 50)

    if not all_posts:
        print("–ü–æ—Å—Ç—ã –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ –ø–æ—Å–ª–µ –æ—Ç—á–µ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ silent
        if silent and errors_list:
            print("\n–û—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–µ–Ω—Ç:", file=sys.stderr)
            for error in errors_list:
                print(f"  {error}", file=sys.stderr)
        return

    for post in all_posts:
        print(f"\n[{post['published'].strftime('%H:%M')}] {post['feed_title']}")
        print(f"  {post['title']}")
        if post["link"]:
            print(f"  –°—Å—ã–ª–∫–∞: {post['link']}")
        if post["description"]:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ–ø–∏—Å–∞–Ω–∏—è
            desc = post["description"][:200]
            if len(post["description"]) > 200:
                desc += "..."
            print(f"  –û–ø–∏—Å–∞–Ω–∏–µ: {desc}")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ –ø–æ—Å–ª–µ –æ—Ç—á–µ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ silent
    if silent and errors_list:
        print("\n–û—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–µ–Ω—Ç:", file=sys.stderr)
        for error in errors_list:
            print(f"  {error}", file=sys.stderr)


# MARK: async_read_posts_wrapper
def async_read_posts_wrapper(
    *,
    feeds: list[dict],
    date_str: str,
    silent: bool = False,
    markdown: bool = False,
):
    """
    –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ read_posts_for_date.

    Args:
        feeds (list): –°–ø–∏—Å–æ–∫ RSS –ª–µ–Ω—Ç
        date_str (str): –î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
        silent (bool): –ù–µ –≤—ã–≤–æ–¥–∏—Ç—å —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        markdown (bool): –í—ã–≤–æ–¥–∏—Ç—å –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown
    """
    asyncio.run(
        read_posts_for_date(
            feeds=feeds, date_str=date_str, silent=silent, markdown=markdown
        )
    )


if __name__ == "__main__":
    main()
