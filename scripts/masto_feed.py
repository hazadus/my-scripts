#!/usr/bin/env -S uv run --quiet --script

# /// script
# dependencies = [
#   "Mastodon.py",
# ]
# ///
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —á—Ç–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –ª–µ–Ω—Ç–µ Mastodon —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Mastodon.py.

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –±—É—Å—Ç–æ–≤ (reblog): –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç—É–∏—Ç–∞ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º,
  —á—Ç–æ —ç—Ç–æ –±—É—Å—Ç –∏ –∫—Ç–æ –µ–≥–æ –∑–∞–±—É—Å—Ç–∏–ª
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–µ–¥–∏–∞-–∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
- –í—ã–≤–æ–¥ –≤ –æ–±—ã—á–Ω–æ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –∏–ª–∏ Markdown

Docs:
- https://github.com/halcy/Mastodon.py?tab=readme-ov-file
- https://mastodonpy.readthedocs.io/en/stable/
"""
import argparse
import datetime as dt
import html
import re

from mastodon import Mastodon

ACCESS_TOKEN_FILE = "toot_usercred.secret"


def parse_date(date_str: str | None) -> dt.date:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏ YYYY-MM-DD –∏–ª–∏ —Ç–µ–∫—É—â—É—é, –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –∑–∞–¥–∞–Ω–∞."""
    if not date_str:
        return dt.date.today()
    try:
        return dt.datetime.strptime(date_str, "%Y-%m-%d").date()
    except ValueError:
        raise SystemExit(
            "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ YYYY-MM-DD, –Ω–∞–ø—Ä–∏–º–µ—Ä 2024-10-31"
        )


def make_client() -> Mastodon:
    return Mastodon(
        access_token=ACCESS_TOKEN_FILE,
        api_base_url="https://fosstodon.org",
    )


def strip_html(content: str) -> str:
    # –£–¥–∞–ª—è–µ–º HTML-—Ç–µ–≥–∏ –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º —Å—É—â–Ω–æ—Å—Ç–∏
    text = re.sub(r"<[^>]+>", "", content)
    return html.unescape(text).strip()


def html_to_markdown(content: str) -> str:
    """–û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä HTML Mastodon-–∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ Markdown.

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –∏ –≥–∏–ø–µ—Ä—Å—Å—ã–ª–∫–∏. –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ç–µ–≥–∏ —É–¥–∞–ª—è—é—Ç—Å—è.
    """
    if not content:
        return ""
    text = content
    # –ü–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    text = re.sub(r"<\s*br\s*/?\s*>", "\n", text, flags=re.IGNORECASE)
    text = re.sub(r"</\s*p\s*>\s*<\s*p\s*>", "\n\n", text, flags=re.IGNORECASE)
    text = re.sub(r"<\s*p\s*>", "", text, flags=re.IGNORECASE)
    text = re.sub(r"</\s*p\s*>", "\n\n", text, flags=re.IGNORECASE)

    # –°—Å—ã–ª–∫–∏: <a href="URL">TEXT</a> -> [TEXT](URL)
    def _link_repl(match: re.Match) -> str:
        url = match.group(1)
        inner = match.group(2)
        inner_clean = re.sub(r"<[^>]+>", "", inner)
        return f"[{html.unescape(inner_clean)}]({url})"

    text = re.sub(
        r"<a[^>]+href=\"([^\"]+)\"[^>]*>(.*?)</a>",
        _link_repl,
        text,
        flags=re.IGNORECASE | re.DOTALL,
    )

    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ—á–∏–µ —Ç–µ–≥–∏
    text = re.sub(r"<[^>]+>", "", text)
    text = html.unescape(text)
    # –ß–∏—Å—Ç–∏–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    text = re.sub(r"\n{3,}", "\n\n", text).strip()
    return text


def fetch_home_for_date(
    mastodon: Mastodon,
    target_date: dt.date,
) -> list[dict]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –¥–æ–º–∞—à–Ω–µ–π –ª–µ–Ω—Ç—ã –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É (–ª–æ–∫–∞–ª—å–Ω–∞—è —Ç–∞–π–º–∑–æ–Ω–∞).

    –î–µ–ª–∞–µ—Ç –ø–∞–≥–∏–Ω–∞—Ü–∏—é –Ω–∞–∑–∞–¥ –ø–æ –≤—Ä–µ–º–µ–Ω–∏, –ø–æ–∫–∞ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –ø–æ—Å—Ç—ã —ç—Ç–æ–π –¥–∞—Ç—ã
    (–∏–ª–∏ –ø–æ–∫–∞ –ª–µ–Ω—Ç–∞ –Ω–µ –∑–∞–∫–æ–Ω—á–∏—Ç—Å—è). –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ ‚Äî –¥–æ 1000 –ø–æ—Å—Ç–æ–≤.
    """
    local_tz = dt.datetime.now().astimezone().tzinfo

    results: list[dict] = []
    max_id = None
    fetched = 0

    while True:
        chunk = mastodon.timeline_home(limit=40, max_id=max_id)
        if not chunk:
            break

        fetched += len(chunk)
        # –û–±–Ω–æ–≤–ª—è–µ–º max_id –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –∫ –±–æ–ª–µ–µ —Å—Ç–∞—Ä—ã–º –ø–æ—Å—Ç–∞–º
        max_id = chunk[-1]["id"]

        for status in chunk:
            created_at = status["created_at"].astimezone(local_tz)
            status_date = created_at.date()
            if status_date == target_date:
                results.append(status)
            # –ï—Å–ª–∏ –ø–æ—Å—Ç —Å—Ç–∞—Ä–µ–µ –Ω—É–∂–Ω–æ–π –¥–∞—Ç—ã, –º–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –ø–∞–≥–∏–Ω–∞—Ü–∏—é,
            # –Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å —É–∂–µ –Ω–µ—á–µ–≥–æ. –ü—Ä–æ–¥–æ–ª–∂–∏–º —Ü–∏–∫–ª, —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è,
            # —á—Ç–æ –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ –≥—Ä–∞–Ω–∏—Ü—É –¥–∞—Ç—ã –≤–Ω—É—Ç—Ä–∏ —á–∞–Ω–∫–∞.

        # –ö—Ä–∏—Ç–µ—Ä–∏–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏: —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π –ø–æ—Å—Ç –≤ —á–∞–Ω–∫–µ —Å—Ç–∞–ª —Å—Ç–∞—Ä–µ–µ –¥–∞—Ç—ã
        oldest_created = chunk[-1]["created_at"].astimezone(local_tz).date()
        if oldest_created < target_date:
            break

        if fetched >= 1000:
            break

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º
    results.sort(key=lambda s: s["created_at"])
    return results


def main() -> None:
    parser = argparse.ArgumentParser(
        description="–ü–æ–∫–∞–∑–∞—Ç—å —Ç—É–∏—Ç—ã (–ø–æ—Å—Ç—ã) –∏–∑ –¥–æ–º–∞—à–Ω–µ–π –ª–µ–Ω—Ç—ã –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É",
    )
    parser.add_argument(
        "date",
        nargs="?",
        help="–î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî —Å–µ–≥–æ–¥–Ω—è)",
    )
    parser.add_argument(
        "--markdown",
        action="store_true",
        help="–í—ã–≤–æ–¥–∏—Ç—å –ø–æ—Å—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown (—Å—Å—ã–ª–∫–∏ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)",
    )
    args = parser.parse_args()

    target_date = parse_date(args.date)
    mastodon = make_client()
    statuses = fetch_home_for_date(mastodon, target_date)

    if not statuses:
        print(f"–ü–æ—Å—Ç–æ–≤ –∑–∞ {target_date.isoformat()} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return

    print(f"–ü–æ—Å—Ç–æ–≤ –∑–∞ {target_date.isoformat()}: {len(statuses)}\n")

    for status in statuses:
        created_at = status["created_at"].astimezone().strftime("%H:%M")
        user = status["account"]["acct"]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –±—É—Å—Ç–æ–º
        is_reblog = status.get("reblog") is not None
        original_status = status.get("reblog") if is_reblog else status

        if args.markdown:
            print("----")
            if is_reblog:
                # –≠—Ç–æ –±—É—Å—Ç - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—É—Å—Ç–µ
                reblogged_user = original_status["account"]["acct"]
                print(
                    f"**üîÑ {created_at} üë§ @{user} –∑–∞–±—É—Å—Ç–∏–ª –ø–æ—Å—Ç –æ—Ç @{reblogged_user}**"
                )
                body = (
                    html_to_markdown(original_status.get("content", ""))
                    or "[–º–µ–¥–∏–∞/–±–µ–∑ —Ç–µ–∫—Å—Ç–∞]"
                )
                print(f"üí¨ {body}")
                # –ú–µ–¥–∏–∞ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è) –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø–æ—Å—Ç–∞
                for media in original_status.get("media_attachments", []) or []:
                    if media.get("type") == "image":
                        alt = media.get("description") or "image"
                        url = (
                            media.get("url")
                            or media.get("remote_url")
                            or media.get("preview_url")
                        )
                        if url:
                            print(f"\n![{alt}]({url})")
                # –°—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª –∑–∞–±—É—Å—Ç–µ–Ω–Ω–æ–≥–æ –ø–æ—Å—Ç–∞
                if original_status.get("url"):
                    print(f"\n[–û—Ç–∫—Ä—ã—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç]({original_status['url']})")
            else:
                # –û–±—ã—á–Ω—ã–π –ø–æ—Å—Ç
                print(f"**üïí {created_at} üë§ @{user}**")
                body = (
                    html_to_markdown(status.get("content", "")) or "[–º–µ–¥–∏–∞/–±–µ–∑ —Ç–µ–∫—Å—Ç–∞]"
                )
                print(f"üí¨ {body}")
                # –ú–µ–¥–∏–∞ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
                for media in status.get("media_attachments", []) or []:
                    if media.get("type") == "image":
                        alt = media.get("description") or "image"
                        url = (
                            media.get("url")
                            or media.get("remote_url")
                            or media.get("preview_url")
                        )
                        if url:
                            print(f"\n![{alt}]({url})")
                # –°—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª –ø–æ—Å—Ç–∞
                if status.get("url"):
                    print(f"\n[–û—Ç–∫—Ä—ã—Ç—å –ø–æ—Å—Ç]({status['url']})")
            print()
        else:
            if is_reblog:
                # –≠—Ç–æ –±—É—Å—Ç - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—É—Å—Ç–µ
                reblogged_user = original_status["account"]["acct"]
                text = (
                    strip_html(original_status.get("content", ""))
                    or "[–º–µ–¥–∏–∞/–±–µ–∑ —Ç–µ–∫—Å—Ç–∞]"
                )
                print(f"{created_at} @{user} –∑–∞–±—É—Å—Ç–∏–ª –æ—Ç @{reblogged_user}: {text}")
            else:
                # –û–±—ã—á–Ω—ã–π –ø–æ—Å—Ç
                text = strip_html(status.get("content", "")) or "[–º–µ–¥–∏–∞/–±–µ–∑ —Ç–µ–∫—Å—Ç–∞]"
                print(f"{created_at} @{user}: {text}")


if __name__ == "__main__":
    main()
